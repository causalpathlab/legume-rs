use crate::deconv::*;
use crate::embed_common::*;
use matrix_util::common_io::*;

use candle_nn::AdamW;
use candle_nn::Optimizer;
use fnv::FnvHashMap as HashMap;
use fnv::FnvHashSet as HashSet;
use indicatif::{ProgressBar, ProgressDrawTarget};
use rand::SeedableRng;

#[derive(Args, Debug)]
pub struct AnnotateTopicArgs {
    #[arg(
        short = 'g',
        long = "gene-dictionary",
        help = "A gene dictionary matrix file (generated by `topic`)",
        long_help = "A gene dictionary matrix file (generated by `topic`)\n\
		      (By default we assume it's logit-scaled). \n\
		      The first column should correspond to features (genes).",
        required = true
    )]
    dict_file: Box<str>,

    ///  (generated by `topic`)
    /// (By default we assume it's logit-scaled).
    #[arg(
        short = 'z',
        long = "latent-topic",
        help = "A latent topic proportion file (generated by `topic`)",
        long_help = "A latent topic proportion file (generated by `topic`)\n\
		      (By default we assume it's logit-scaled). \n\
		      The first column should correspond to features (genes).",
        required = true
    )]
    latent_file: Box<str>,

    #[arg(
        short = 'm',
        long = "marker-genes",
        help = "A marker feature file",
        long_help = "A marker feature file, e.g., mapping genes to cell types. \n\
		     Each line contains two names: \n\
		     (1) gene and \n\
		     (2) cell type \n\
		     (tab-separated or comma-separated). \n\
		     We allow space but will replace it with '_'.",
        required = true
    )]
    marker_file: Box<str>,

    #[arg(
        long,
        short = 'i',
        default_value_t = 1000,
        help = "Number of training epochs.",
        long_help = "Number of training epochs.\n\
		     Controls how many times a Poisson regression is trained."
    )]
    epochs: usize,

    #[arg(
        short = 'c',
        long,
        default_value_t = 1e4,
        help = "Column sum normalization scale.",
        long_help = "Column sum normalization to scale the model parameters."
    )]
    column_sum_norm: f32,

    #[arg(
        long,
        short,
        required = true,
        help = "Output header",
        long_help = "Output header for results.\n\
		     Specify the output file or prefix for generated files."
    )]
    out: Box<str>,

    #[arg(
        long,
        short,
        help = "Verbosity.",
        long_help = "Enable verbose output.\n\
		     Prints additional information during execution."
    )]
    verbose: bool,
}

pub fn annotate_topics(args: &AnnotateTopicArgs) -> anyhow::Result<()> {
    if args.verbose {
        std::env::set_var("RUST_LOG", "info");
    }
    env_logger::init();

    // 1. read dictionary and latent states
    let MatWithNames {
        rows: row_names,
        cols: _topics,
        mat: log_dict_dk,
    } = read_mat(&args.dict_file)?;

    info!(
        "Read dictionary {} x {}",
        log_dict_dk.nrows(),
        log_dict_dk.ncols()
    );

    let MatWithNames {
        rows: cell_names,
        cols: topic_names,
        mat: topic_nt,
    } = read_mat(&args.latent_file)?;

    // 2. read marker gene annotation
    let AnnotInfo {
        membership_ga,
        annot_names,
    } = build_annotation_matrix(&args.marker_file, &row_names)?;

    let nnz_features = membership_ga
        .column_sum()
        .into_iter()
        .filter(|&x| *x > 0.0)
        .count();

    info!(
        "Found {} cell types matched over {} features",
        annot_names.len(),
        nnz_features
    );

    // 3. associate topics to cell types
    // assume a simple Poisson regression model

    use rand_distr::{Distribution, Poisson};

    let dev = candle_core::Device::Cpu;
    let parameters = candle_nn::VarMap::new();
    let param_builder =
        candle_nn::VarBuilder::from_varmap(&parameters, candle_core::DType::F32, &dev);

    let model = poission_deconv(
        log_dict_dk.nrows(),
        log_dict_dk.ncols(),
        membership_ga.ncols(),
        param_builder,
    )?;

    let mut adam = AdamW::new_lr(parameters.all_vars(), 1e-2)?;

    let pb = ProgressBar::new(args.epochs as u64);

    if args.verbose {
        pb.set_draw_target(ProgressDrawTarget::hidden());
    }

    let x_ga = membership_ga.to_tensor(&dev)?;

    for epoch in 0..args.epochs {
        // 1. Sample Y[g,t] ~ Poisson(Î²[g,t] * N)
        let mut rng = rand::rngs::StdRng::seed_from_u64(epoch as u64 + 1);
        let y_gt = log_dict_dk
            .map(|x| {
                Poisson::new(x.exp() * args.column_sum_norm)
                    .unwrap()
                    .sample(&mut rng)
            })
            .to_tensor(&dev)?;

        let loss = model.log_likelihood(&y_gt, &x_ga)?.neg()?.sum_all()?;
        adam.backward_step(&loss)?;
        let loss_val: f32 = loss.to_scalar()?;
        pb.inc(1);

        if args.verbose {
            info!("[{}] log-likelihood={}", epoch, -loss_val);
        }
    }

    let annot_topic_file = format!("{}.annotation_topic.parquet", args.out);
    let cell_annot_file = format!("{}.annotation.parquet", args.out);

    // 2. full predict annotations
    let aa_annot_topic = Mat::from_tensor(&model.log_pip()?.exp()?)?;
    let topic_tn = topic_nt.map(|x| x.exp()).transpose().normalize_columns();
    let topic_annot = (&aa_annot_topic * topic_tn).normalize_columns().transpose();

    aa_annot_topic.to_parquet(Some(&annot_names), Some(&topic_names), &annot_topic_file)?;
    topic_annot.to_parquet(Some(&cell_names), Some(&annot_names), &cell_annot_file)?;

    Ok(())
}

fn read_mat(file_path: &str) -> anyhow::Result<MatWithNames<Mat>> {
    Ok(match file_ext(file_path)?.as_ref() {
        "parquet" => Mat::from_parquet(file_path)?,
        _ => Mat::read_data(file_path, &['\t', ','], None, Some(0), None, None)?,
    })
}

fn read_marker_gene_info(file_path: &str) -> anyhow::Result<HashMap<Box<str>, Box<str>>> {
    let ReadLinesOut { lines, header: _ } =
        read_lines_of_words_delim(&file_path, &['\t', ','], -1)?;

    Ok(lines
        .into_iter()
        .filter_map(|words| {
            if words.len() < 2 {
                None
            } else {
                Some((words[0].clone(), words[1].clone()))
            }
        })
        .collect())
}

fn build_annotation_matrix(
    marker_gene_path: &str,
    row_names: &[Box<str>],
) -> anyhow::Result<AnnotInfo> {
    let gene_to_type = read_marker_gene_info(marker_gene_path)?;

    if gene_to_type.is_empty() {
        return Err(anyhow::anyhow!("empty/invalid marker gene information"));
    }

    let mut row_to_type_vec = vec![];

    for (ri, rn) in row_names.iter().enumerate() {
        if let Some(t) = gene_to_type.get(rn) {
            row_to_type_vec.push((ri, t));
        }

        for h in rn.split(&['_']) {
            if let Some(t) = gene_to_type.get(h) {
                row_to_type_vec.push((ri, t));
            }
        }
    }

    row_to_type_vec.sort();
    row_to_type_vec.dedup();

    let mut id_to_celltypes: Vec<Box<str>> = row_to_type_vec
        .iter()
        .map(|&(_, t)| t.clone())
        .collect::<HashSet<_>>()
        .into_iter()
        .collect();

    id_to_celltypes.sort();

    let celltype_to_id: HashMap<Box<str>, usize> = id_to_celltypes
        .iter()
        .enumerate()
        .map(|(i, x)| (x.clone(), i))
        .collect();

    let triplets = row_to_type_vec
        .iter()
        .filter_map(|&(r, ct)| {
            if let Some(t) = celltype_to_id.get(ct) {
                Some((r, *t, 1.0))
            } else {
                None
            }
        })
        .collect::<Vec<_>>();

    let nrow = row_names.len();
    let ncol = id_to_celltypes.len();

    // gene x annotation group
    let membership_ga = Mat::from_nonzero_triplets(nrow, ncol, &triplets)?;

    // remove potential ' '
    let annot_names = id_to_celltypes
        .into_iter()
        .map(|x| x.replace(" ", "_").into_boxed_str())
        .collect();

    Ok(AnnotInfo {
        membership_ga,
        annot_names,
    })
}

struct AnnotInfo {
    membership_ga: Mat,
    annot_names: Vec<Box<str>>,
}
