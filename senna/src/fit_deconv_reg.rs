use core::f32;

use crate::embed_common::*;
use crate::routines_pre_process::*;

use dashmap::DashMap as HashMap;
use matrix_util::common_io::*;
use matrix_util::dmatrix_util::*;

#[derive(Args, Debug)]
pub struct DeconvRegArgs {
    /// gene dictionary matrix file (generated by `topic`)
    /// (By default we assume it's logit-scaled).
    #[arg(short = 'g', long, required = true)]
    dict_file: Box<str>,

    /// bulk data files (`.parquet`, `.tsv.gz`, or `.csv.gz`)
    /// where the first column corresponds to gene names
    #[arg(short = 'x', long, required = true)]
    bulk_data_files: Vec<Box<str>>,

    /// single-cell data (`.zarr` or `.h5`)
    #[arg(short = 's', long, value_delimiter = ',')]
    sc_data_files: Option<Vec<Box<str>>>,

    /// batch membership files (comma-separated names). Each bach file
    /// should correspond to each data file.
    #[arg(long, short, value_delimiter(','))]
    batch_files: Option<Vec<Box<str>>>,

    /// output header
    #[arg(long, short, required = true)]
    out: Box<str>,
}

struct BulkDataOut {
    genes: Vec<Box<str>>,
    samples: Vec<Box<str>>,
    data: Mat,
}

fn read_mat(file_path: &str) -> anyhow::Result<MatWithNames<Mat>> {
    Ok(match extension(file_path)?.as_ref() {
        "parquet" => Mat::from_parquet(file_path)?,
        _ => Mat::read_data(file_path, &['\t', ','], None, Some(0), None, None)?,
    })
}

fn read_bulk_files(
    bulk_data_files: &[Box<str>],
    genes: &Vec<Box<str>>,
) -> anyhow::Result<BulkDataOut> {
    let gene_to_position: HashMap<Box<str>, usize> = genes
        .iter()
        .enumerate()
        .map(|(i, x)| (x.clone(), i))
        .collect();

    let ngenes = gene_to_position.len();
    info!("use {} genes as common features", ngenes);

    let mut samples = vec![];
    let mut bulk_data_vec = vec![];

    for bulk_file in bulk_data_files {
        let MatWithNames {
            rows: raw_genes,
            cols: raw_samples,
            mat: raw_ds,
        } = read_mat(bulk_file.as_ref())?;

        let ncols = raw_samples.len();

        let mut padded_ds = Mat::zeros(ngenes, ncols);
        for (i, g) in raw_genes.iter().enumerate() {
            if let Some(r) = gene_to_position.get(g) {
                padded_ds.row_mut(*r.value()).copy_from(&raw_ds.row(i));
            }
        }

        samples.extend(raw_samples);
        bulk_data_vec.push(padded_ds);
    }

    let bulk_data = concatenate_horizontal(&bulk_data_vec)?;

    info!(
        "Read bulk data {} genes x {} samples",
        ngenes,
        samples.len()
    );
    Ok(BulkDataOut {
        genes: genes.to_vec(),
        samples,
        data: bulk_data,
    })
}

pub fn fit_deconv_reg(args: &DeconvRegArgs) -> anyhow::Result<()> {
    let MatWithNames {
        rows: sc_genes,
        cols: _samples,
        mat: dict_dk,
    } = read_mat(&args.dict_file)?;

    info!("Read dictionary {} x {}", dict_dk.nrows(), dict_dk.ncols());

    let BulkDataOut {
        genes: _genes,
        samples: bulk_samples,
        data: bulk_dm,
    } = read_bulk_files(&args.bulk_data_files, &sc_genes)?;

    info!("Read bulk {} data file[s]", args.bulk_data_files.len());

    let bulk_cor_km = bulk_dm.correlate(&dict_dk)?;

    if let Some(sc_data_files) = args.sc_data_files.as_ref() {
        let SparseDataWithBatch {
            data: sc_data,
            batch: _batch,
        } = read_sparse_data_with_membership(ReadArgs {
            data_files: sc_data_files.clone(),
            batch_files: args.batch_files.clone(),
        })?;

        info!("Read single-cell data files");

        let sc_cor_kn = sc_data.correlate(&dict_dk)?;
        sc_cor_kn.transpose().to_parquet(
            Some(sc_data.column_names()?.as_ref()),
            None,
            &(args.out.to_string() + ".deconv.sc.parquet"),
        )?;
    }

    bulk_cor_km.transpose().to_parquet(
        Some(&bulk_samples),
        None,
        &(args.out.to_string() + ".deconv.parquet"),
    )?;

    Ok(())
}

trait CorrelateWithDictionary {
    /// `Σ_g ln(β[g,k]) * y[g,j] / Σ_g y[g,j]`
    fn correlate(&self, logits_dict_dk: &Mat) -> anyhow::Result<Mat>;
}

impl CorrelateWithDictionary for Mat {
    fn correlate(&self, logits_dict_dk: &Mat) -> anyhow::Result<Mat> {
        let denom_1n = self.row_sum().map(|x| x.clamp(1.0, f32::INFINITY));

        let mut ret = logits_dict_dk.transpose() * self.map(|x| x.clamp(0.0, f32::INFINITY));

        ret.row_iter_mut().for_each(|mut x| {
            x.component_div_assign(&denom_1n);
        });
        Ok(ret)
    }
}

impl CorrelateWithDictionary for SparseIoVec {
    fn correlate(&self, dict_dk: &Mat) -> anyhow::Result<Mat> {
        let mut cor_kn = Mat::zeros(dict_dk.ncols(), self.num_columns()?);
        self.visit_columns_by_block(&cor_with_dict, dict_dk, &mut cor_kn, None)?;
        Ok(cor_kn)
    }
}

fn cor_with_dict(
    (lb, ub): (usize, usize),
    data: &SparseIoVec,
    logits_dict_dk: &Mat,
    arc_num_kn: Arc<Mutex<&mut Mat>>,
) -> anyhow::Result<()> {
    let x_dn = data.read_columns_csc(lb..ub)?;
    let mut ret = (x_dn.transpose() * logits_dict_dk)
        .transpose()
        .map(|x| x.clamp(0.0, f32::INFINITY));
    let denom_1n =
        &x_dn * Mat::from_element(x_dn.ncols(), 1, 1.0).map(|x| x.clamp(1.0, f32::INFINITY));
    ret.row_iter_mut().for_each(|mut x| {
        x.component_div_assign(&denom_1n);
    });
    let mut cor_kn = arc_num_kn.lock().expect("lock");
    cor_kn.columns_range_mut(lb..ub).copy_from(&ret);
    Ok(())
}
