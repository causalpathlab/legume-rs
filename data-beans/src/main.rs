mod handlers;
mod interactive;
mod misc;
mod qc;
mod simulate;
mod simulate_deconv;
mod sparse_data_visitors;
mod sparse_io;
mod sparse_io_vector;
mod sparse_matrix_hdf5;
mod sparse_matrix_zarr;
mod sparse_util;
mod utilities;

use crate::handlers::analysis::{run_stat, run_simulate};
use crate::handlers::builders::{run_build_from_mtx, run_build_from_h5_triplets, run_build_from_zarr_triplets};
use crate::handlers::inspection::{show_info, take_columns, take_rows, take_column_names, take_row_names};
use crate::handlers::listing::{list_h5, list_zarr};
use crate::handlers::merging::{run_merge_backend, run_merge_mtx, align_backends};
use crate::handlers::transformation::{subset_columns, subset_rows, reorder_rows, run_squeeze};
use crate::sparse_io::*;
use crate::sparse_util::IndexPointerType;

use clap::{ArgAction, Args, Parser, Subcommand, ValueEnum};
use simulate_deconv::generate_convoluted_data;
use simulate_deconv::SimConvArgs;

fn main() -> anyhow::Result<()> {
    env_logger::init();

    let cli = Cli::parse();

    match &cli.commands {
        Commands::FromMtx(args) => {
            run_build_from_mtx(args)?;
        }
        Commands::ListH5(args) => {
            list_h5(args)?;
        }
        Commands::ListZarr(args) => {
            list_zarr(args)?;
        }
        Commands::FromZarr(args) => {
            run_build_from_zarr_triplets(args)?;
        }
        Commands::FromH5ad(args) => {
            run_build_from_h5_triplets(args)?;
        }
        Commands::Simulate(args) => {
            run_simulate(args)?;
        }
        Commands::SimulateConv(args) => {
            generate_convoluted_data(args)?;
        }
        Commands::Info(args) => {
            show_info(args)?;
        }
        Commands::Statistics(args) => {
            run_stat(args)?;
        }
        Commands::Squeeze(args) => {
            run_squeeze(args)?;
        }
        Commands::Columns(args) => {
            take_columns(args)?;
        }
        Commands::Rows(args) => {
            take_rows(args)?;
        }
        Commands::ColumnNames(args) => {
            take_column_names(args)?;
        }
        Commands::RowNames(args) => {
            take_row_names(args)?;
        }
        Commands::SubsetColumns(args) => {
            subset_columns(args)?;
        }
        Commands::SubsetRows(args) => {
            subset_rows(args)?;
        }
        Commands::AlignData(args) => {
            align_backends(args)?;
        }
        Commands::ReorderRows(args) => {
            reorder_rows(args)?;
        }
        Commands::MergeMtx(args) => {
            run_merge_mtx(args)?;
        }
        Commands::MergeBackend(args) => {
            run_merge_backend(args)?;
        }
    }

    Ok(())
}

#[derive(Parser, Debug)]
#[command(
    version,
    about = "Basic utility functions for processing a sparse matrix.",
    long_about = "Basic utility functions for processing a sparse matrix.

We assume non-negative sparse matrices were generated by single-cell omics (feature x cell).
This tool creates a data structure for faster access, organized as follows:

    (root)
        ├── nrow
        ├── ncell
        ├── by_column
        │   ├── data
        │   ├── indices (row indices)
        │   └── indptr (column pointers)
        └── by_row
            ├── data
            ├── indices (column indices)
            └── indptr (row pointers)

For more details on each command, use '--help' after the command name."
)]
struct Cli {
    #[command(subcommand)]
    commands: Commands,
}

#[derive(Subcommand, Debug)]
enum Commands {
    #[command(about = "Build backend from `mtx` file and associated `tsv` files")]
    FromMtx(FromMtxArgs),

    #[command(
        about = "Build backend from triplets in `h5` (AnnData)",
        visible_alias = "from-h5"
    )]
    FromH5ad(FromH5Args),

    #[command(
        about = "Build backend from triplets in 10X Xenium `zarr`",
        long_about = "Build a backend from triplets in `zarr` format.\n\
		      Supports conversion and indexing for fast access."
    )]
    FromZarr(FromZarrArgs),

    #[command(
        about = "List contents of `h5` file",
        long_about = "List what are included in the `h5` file.\n\
		      Shows datasets, groups, and metadata."
    )]
    ListH5(ListH5Args),

    #[command(
        about = "List contents of `zarr` file",
        long_about = "List what are included in the `zarr` file.\n\
		      Displays structure and available arrays."
    )]
    ListZarr(ListZarrArgs),

    #[command(
        about = "Sort rows by name order",
        long_about = "Sort rows according to the order of row names specified in a row name file.\n\
		      Useful for aligning datasets and ensuring consistent row order."
    )]
    ReorderRows(ReorderRowsArgs),

    #[command(
        about = "Take columns and output dense matrix",
        long_about = "Take columns from the sparse matrix and save them to an `output` file as a dense matrix for quick examination.\n\
		      Useful for extracting subsets for visualization or analysis."
    )]
    Columns(TakeColumnsArgs),

    #[command(
        about = "Take rows and output dense matrix (transposed)",
        long_about = "Take rows from the sparse matrix and save them to an `output` file as a dense matrix for quick examination.\n\
		      For convenience, it will output a transposed (`column x selected_row`) matrix."
    )]
    Rows(TakeRowsArgs),

    #[command(
        about = "List column names",
        long_about = "List all column names in the backend.\n\
		      Useful for inspecting available features."
    )]
    ColumnNames(TakeColumnNamesArgs),

    #[command(
        about = "List row names",
        long_about = "List all row names in the backend.\n\
		      Useful for inspecting available samples or observations."
    )]
    RowNames(TakeRowNamesArgs),

    #[command(
        about = "Subset columns and create new backend",
        long_about = "Take columns from the sparse matrix and create a new sparse matrix backend.\n\
		      Allows for focused analysis on selected features."
    )]
    SubsetColumns(SubsetColumnsArgs),

    #[command(
        about = "Subset rows and create new backend",
        long_about = "Take rows from the sparse matrix and create a new sparse matrix backend.\n\
		      Allows for focused analysis on selected samples/observations."
    )]
    SubsetRows(SubsetRowsArgs),

    #[command(
        about = "Align data backends",
        long_about = "To ensure that column names are aligned for multimodal analysis.\n\
		      We will only keep columns and rows matched across files.\n\
		      1st row: `D(1,1)-D(1,2)`, 2nd row: `D(2,1)-D(2,2)`, etc.",
        visible_alias = "align"
    )]
    AlignData(AlignDataArgs),

    #[command(
        about = "Merge multiple `.mtx` files",
        long_about = "Merge multiple 10x `.mtx` files into one fileset.\n\
		      Useful for combining datasets from different sources."
    )]
    MergeMtx(MergeMtxArgs),

    #[command(
        about = "Merge multiple backend files",
        long_about = "Merge multiple backend file(sets) into one.\n\
		      Supports various formats and options for merging.",
        visible_alias = "merge"
    )]
    MergeBackend(MergeBackendArgs),

    #[command(
        about = "Squeeze out sparse rows/columns",
        long_about = "Squeeze out rows and columns with too few non-zeros.\n\
		      It will overwrite the original (be careful) and save the indices kept."
    )]
    Squeeze(RunSqueezeArgs),

    #[command(
        about = "Show basic matrix info",
        long_about = "Show basic information of a sparse matrix.\n\
		      If output header is provided, row and column names will be saved."
    )]
    Info(InfoArgs),

    #[command(
        about = "Take matrix statistics",
        long_about = "Take basic statistics from a sparse matrix.\n\
		      The output file will contain columns of \n\
		      (1) `nnz` - number of non-zero elements, \n\
		      (2) `tot` - total sum, \n\
		      (3) `mu` - average `μ`, \n\
		      (4) `sig` - standard deviation `σ`.",
        visible_alias = "stat"
    )]
    Statistics(RunStatArgs),

    #[command(
        about = "Simulate matrix with Gamma topic",
        long_about = "`Y(i,j) ~ δ(i,B(j)) Σ β(i,k) θ(j,k)` with β,θ ~ Gamma topic;\n\
		      B(j)`=batch; `ln δ`~N(0,1)"
    )]
    Simulate(RunSimulateArgs),

    #[command(about = "Simulate convoluted data matrix (experimental)")]
    SimulateConv(SimConvArgs),
}

#[derive(Args, Debug)]
pub struct ReorderRowsArgs {
    /// Data file -- either `.zarr` or `.h5`
    data_file: Box<str>,

    /// Row/feature name file (name per each line; `.tsv.gz` or `.tsv`)
    #[arg(short, long, required = true)]
    row_file: Box<str>,

    /// output header
    #[arg(short, long, required = true)]
    output: Box<str>,
}

#[derive(Args, Debug)]
pub struct TakeColumnsArgs {
    /// data file -- either `.zarr` or `.h5`
    data_file: Box<str>,

    /// column indices to take: e.g., `0,1,2,3`
    #[arg(short = 'i', long, value_delimiter = ',')]
    column_indices: Option<Vec<usize>>,

    /// column name file where each line is a column name
    #[arg(short = 'f', long)]
    name_file: Option<Box<str>>,

    /// column names to take: e.g., `col1,col2,col3` (supports substring matching)
    #[arg(short = 'n', long, value_delimiter = ',')]
    column_names: Option<Vec<Box<str>>>,

    /// output `parquet` file
    #[arg(short, long, default_value = "stdout")]
    output: Box<str>,
}

#[derive(Args, Debug)]
pub struct TakeRowsArgs {
    /// data file -- either `.zarr` or `.h5`
    data_file: Box<str>,

    /// row indices to take: e.g., `0,1,2,3`
    #[arg(short = 'i', long, value_delimiter = ',')]
    row_indices: Option<Vec<usize>>,

    /// row name file where each line is a row name
    #[arg(short = 'f', long)]
    name_file: Option<Box<str>>,

    /// row names to take: e.g., `gene1,gene2,gene3` (supports substring matching)
    #[arg(short = 'n', long, value_delimiter = ',')]
    row_names: Option<Vec<Box<str>>>,

    /// output `parquet` file
    #[arg(short, long, default_value = "stdout")]
    output: Box<str>,
}

#[derive(Args, Debug)]
pub struct TakeColumnNamesArgs {
    /// data file -- either `.zarr` or `.h5`
    data_file: Box<str>,

    /// output file
    #[arg(short, long, default_value = "stdout")]
    output: Box<str>,
}

#[derive(Args, Debug)]
pub struct TakeRowNamesArgs {
    /// data file -- either `.zarr` or `.h5`
    data_file: Box<str>,

    /// output file
    #[arg(short, long, default_value = "stdout")]
    output: Box<str>,
}

#[derive(Args, Debug)]
pub struct SubsetColumnsArgs {
    /// data file -- either `.zarr` or `.h5`
    data_file: Box<str>,

    /// column indices to take: e.g., `0,1,2,3`
    #[arg(short = 'i', long, value_delimiter = ',')]
    column_indices: Option<Vec<usize>>,

    /// column name file where each line is a column name
    #[arg(short = 'f', long)]
    name_file: Option<Box<str>>,

    /// delimiter for base-key extraction (e.g., '@' to match "ACGT-1@batch" with "ACGT-1")
    #[arg(short = 'd', long, default_value = "@")]
    delimiter: char,

    /// enable prefix matching (stored name is prefix of query or vice versa)
    #[arg(long, default_value_t = true)]
    allow_prefix: bool,

    /// squeeze
    #[arg(long, default_value_t = false)]
    do_squeeze: bool,

    /// minimum number of non-zero cutoff for rows
    #[arg(long, default_value_t = 1)]
    row_nnz_cutoff: usize,

    /// minimum number of non-zero cutoff for columns
    #[arg(long, default_value_t = 1)]
    column_nnz_cutoff: usize,

    /// output file
    #[arg(short, long, required = true)]
    output: Box<str>,
}

#[derive(Args, Debug)]
pub struct SubsetRowsArgs {
    /// data file -- either `.zarr` or `.h5`
    data_file: Box<str>,

    /// row indices to take: e.g., `0,1,2,3`
    #[arg(short = 'i', long, value_delimiter = ',')]
    row_indices: Option<Vec<usize>>,

    /// row name file where each line is a row name
    #[arg(short = 'f', long)]
    name_file: Option<Box<str>>,

    /// delimiter for base-key extraction (e.g., '@' to match "gene@batch" with "gene")
    #[arg(short = 'd', long, default_value = "@")]
    delimiter: char,

    /// enable prefix matching (stored name is prefix of query or vice versa)
    #[arg(long, default_value_t = true)]
    allow_prefix: bool,

    /// squeeze
    #[arg(long, default_value_t = false)]
    do_squeeze: bool,

    /// minimum number of non-zero cutoff for rows
    #[arg(long, default_value_t = 1)]
    row_nnz_cutoff: usize,

    /// minimum number of non-zero cutoff for columns
    #[arg(long, default_value_t = 1)]
    column_nnz_cutoff: usize,

    /// output file
    #[arg(short, long, required = true)]
    output: Box<str>,
}

#[derive(Args, Debug)]
pub struct AlignDataArgs {
    /// data file -- either `.zarr` or `.h5`
    #[arg(required = true)]
    data_files: Vec<Box<str>>,

    /// Data types (treating them as different rows)
    #[arg(short = 'r', long, required = true)]
    num_data_types: usize,

    /// output directory
    #[arg(short, long, required = true)]
    output_directory: Box<str>,
}

#[derive(Args, Debug)]
pub struct FromMtxArgs {
    /// matrix market-formatted data file (`.mtx.gz` or `.mtx`)
    mtx: Box<str>,

    /// row/feature name file (name per each line; `.tsv.gz` or `.tsv`)
    #[arg(short, long)]
    row: Option<Box<str>>,

    /// column/cell/barcode file (name per each line; `.tsv.gz` or `.tsv`)
    #[arg(short, long)]
    col: Option<Box<str>>,

    /// backend for the output file
    #[arg(long, value_enum, default_value = "zarr")]
    backend: SparseIoBackend,

    /// output file header: {output}.{backend}
    #[arg(short, long)]
    output: Box<str>,

    /// squeeze
    #[arg(long, default_value_t = false)]
    do_squeeze: bool,

    /// minimum number of non-zero cutoff for rows
    #[arg(long, default_value_t = 1)]
    row_nnz_cutoff: usize,

    /// minimum number of non-zero cutoff for columns
    #[arg(long, default_value_t = 1)]
    column_nnz_cutoff: usize,

    /// verbose mode
    #[arg(short, long, action = ArgAction::Count)]
    verbose: u8,
}

#[derive(Args, Debug)]
pub struct ListH5Args {
    h5_file: Box<str>,
}

#[derive(Args, Debug)]
pub struct ListZarrArgs {
    zarr_file: Box<str>,
}

#[derive(Args, Debug)]
pub struct FromH5Args {
    #[arg(
        help = "Input HDF5 file containing sparse matrix triplets",
        long_help = "Specify the HDF5 file where triplets of sparse matrix data are stored. \n\
		     Supports 10X Genomics and H5AD formats."
    )]
    h5_file: Box<str>,

    #[arg(
        long,
        value_enum,
        default_value = "zarr",
        help = "Backend format for output",
        long_help = "Choose the backend format for the output file. \n\
		     Supported formats include 'zarr' and 'h5'"
    )]
    backend: SparseIoBackend,

    #[arg(
        short,
        long,
        help = "Output file header or name",
        long_help = "Specify the output file header. \n\
		     The output will be named as {output}.{backend}.\n\
		     Redundant {backend} names will be ignored."
    )]
    output: Box<str>,

    #[arg(
        short = 'x',
        long,
        default_value = "matrix",
        help = "Root group name for sparse data triplets",
        long_help = "Set the root group name under which sparse data triplets are stored in the HDF5 file. \n\
		     Use the 'list-h5' command to inspect available groups."
    )]
    root_group_name: Box<str>,

    #[arg(
        short = 'd',
        long,
        default_value = "data",
        help = "Data field name",
        long_help = "Name of the dataset containing triplet values X(i,j) under the root group."
    )]
    data_field: Box<str>,

    #[arg(
        short = 'i',
        long,
        default_value = "indices",
        help = "Indices field name",
        long_help = "Name of the dataset containing indices. \n\
		     Row indices for CSC, column indices for CSR, under the root group."
    )]
    indices_field: Box<str>,

    #[arg(
        short = 'p',
        long,
        default_value = "indptr",
        help = "Indptr field name",
        long_help = "Name of the dataset containing indptr. \n\
		     Column pointers for CSC, row pointers for CSR, under the root group."
    )]
    indptr_field: Box<str>,

    #[arg(
        short = 't',
        long,
        value_enum,
        default_value = "column",
        help = "Pointer type (row or column)",
        long_help = "Specify whether the pointers are for row (gene) or column (cell) indices."
    )]
    pointer_type: IndexPointerType,

    #[arg(
        short = 'r',
        long,
        default_value = "features/id",
        help = "Row ID field name",
        long_help = "Group or dataset name for row, gene, or feature IDs under the root group."
    )]
    row_id_field: Box<str>,

    #[arg(
        short = 'n',
        long,
        default_value = "features/name",
        help = "Row name field name",
        long_help = "Group or dataset name for row, gene, or feature names under the root group."
    )]
    row_name_field: Box<str>,

    #[arg(
        short = 'f',
        long,
        default_value = "features/feature_type",
        help = "Row type field name",
        long_help = "Group or dataset name for row, gene, or feature types under the root group."
    )]
    row_type_field: Box<str>,

    #[arg(
        long,
        default_value = "gene",
        help = "Select row type",
        long_help = "Select row type for inclusion. Rows are included if their type contains this value."
    )]
    select_row_type: Box<str>,

    #[arg(
        long,
        default_value = "aggregate",
        help = "Remove row type",
        long_help = "Remove rows if their type contains this value."
    )]
    remove_row_type: Box<str>,

    #[arg(
        short = 'c',
        long,
        default_value = "barcodes",
        help = "Column name field",
        long_help = "Group or dataset name for columns or cells under the root group."
    )]
    column_name_field: Box<str>,

    #[arg(
        long,
        default_value_t = false,
        help = "Squeeze sparse rows or columns",
        long_help = "Enable squeezing to remove rows and columns with too few non-zeros. \n\
		     This can help reduce file size and improve performance."
    )]
    do_squeeze: bool,

    #[arg(
        long,
        default_value_t = 1,
        help = "Row non-zero cutoff",
        long_help = "Minimum number of non-zero elements required for rows. \n\
		     Rows with fewer non-zeros will be removed if squeezing is enabled."
    )]
    row_nnz_cutoff: usize,

    #[arg(
        long,
        default_value_t = 1,
        help = "Column non-zero cutoff",
        long_help = "Minimum number of non-zero elements required for columns. \n\
		     Columns with fewer non-zeros will be removed if squeezing is enabled."
    )]
    column_nnz_cutoff: usize,

    #[arg(
        short,
        long,
        action = clap::ArgAction::Count,
        help = "Verbose mode",
        long_help = "Enable verbose mode for more detailed output. \n\
		     Use multiple times for increased verbosity."
    )]
    verbose: u8,
}

#[derive(clap::Args, Debug)]
pub struct FromZarrArgs {
    #[arg(
        help = "Input Zarr file containing sparse matrix triplets",
        long_help = "Specify the Zarr file where triplets of sparse matrix data are stored. \n\
		     For example, 10X Genomics Xenium's 'cell_feature_matrix.zarr.zip'."
    )]
    zarr_file: Box<str>,

    #[arg(
        long,
        value_enum,
        default_value = "zarr",
        help = "Backend format for output",
        long_help = "Choose the backend format for the output file. \n\
		     Supported formats include 'zarr' and 'h5'."
    )]
    backend: SparseIoBackend,

    #[arg(
        short,
        long,
        help = "Output file header or name",
        long_help = "Specify the output file header. \n\
		     The output will be named as {output}.{backend}.\n\
		     Redundant {backend} names will be ignored."
    )]
    output: Box<str>,

    #[arg(
        short = 'd',
        long,
        default_value = "/cell_features/data",
        help = "Data field path",
        long_help = "Path to the dataset containing triplet values. \n\
		     Use the 'list-zarr' subcommand to inspect available fields."
    )]
    data_field: Box<str>,

    #[arg(
        short = 'i',
        long,
        default_value = "/cell_features/indices",
        help = "Indices field path",
        long_help = "Path to the dataset containing indices. \n\
		     Row indices for CSC, column indices for CSR."
    )]
    indices_field: Box<str>,

    #[arg(
        short = 'p',
        long,
        default_value = "/cell_features/indptr",
        help = "Indptr field path",
        long_help = "Path to the dataset containing indptr. \n\
		     Column pointers for CSC, row pointers for CSR."
    )]
    indptr_field: Box<str>,

    #[arg(
        short = 't',
        long,
        value_enum,
        default_value = "row",
        help = "Pointer type (row or column)",
        long_help = "Specify whether the pointers keep track of row (gene) or column (cell) indices."
    )]
    pointer_type: IndexPointerType,

    #[arg(
        short = 'r',
        long,
        default_value = "/cell_features/feature_ids",
        help = "Row ID field path",
        long_help = "Path to the group or dataset for row, gene, or feature IDs."
    )]
    row_id_field: Box<str>,

    #[arg(
        short = 'n',
        long,
        default_value = "/cell_features/feature_keys",
        help = "Row name field path",
        long_help = "Path to the group or dataset for row, gene, or feature names."
    )]
    row_name_field: Box<str>,

    #[arg(
        short = 'f',
        long,
        default_value = "/cell_features/feature_types",
        help = "Row type field path",
        long_help = "Path to the group or dataset for row, gene, or feature types."
    )]
    row_type_field: Box<str>,

    #[arg(
        long,
        default_value = "gene",
        help = "Select row type",
        long_help = "Select row type for inclusion. Rows are included if their type contains this value."
    )]
    select_row_type: Box<str>,

    #[arg(
        long,
        default_value = "aggregate",
        help = "Remove row type",
        long_help = "Remove rows if their type contains this value."
    )]
    remove_row_type: Box<str>,

    #[arg(
        short = 'c',
        long,
        default_value = "/cell_features/cell_id",
        help = "Column name field path",
        long_help = "Path to the group or dataset for columns or cells. \n\
		     Will first attempt Xenium's Cell ID format mapping."
    )]
    column_name_field: Box<str>,

    #[arg(
        long,
        default_value_t = false,
        help = "Squeeze sparse rows or columns",
        long_help = "Enable squeezing to remove rows and columns with too few non-zeros. \n\
		     This can help reduce file size and improve performance."
    )]
    do_squeeze: bool,

    #[arg(
        long,
        default_value_t = 1,
        help = "Row non-zero cutoff",
        long_help = "Minimum number of non-zero elements required for rows. \n\
		     Rows with fewer non-zeros will be removed if squeezing is enabled."
    )]
    row_nnz_cutoff: usize,

    #[arg(
        long,
        default_value_t = 1,
        help = "Column non-zero cutoff",
        long_help = "Minimum number of non-zero elements required for columns. \n\
		     Columns with fewer non-zeros will be removed if squeezing is enabled."
    )]
    column_nnz_cutoff: usize,

    #[arg(
        short,
        long,
        action = clap::ArgAction::Count,
        help = "Verbose mode",
        long_help = "Enable verbose mode for more detailed output. \n\
		     Use multiple times for increased verbosity."
    )]
    verbose: u8,
}

#[derive(Args, Debug)]
pub struct MergeBackendArgs {
    #[arg(
        help = "Input data files",
        long_help = "Data files to be merged into a single backend. \n\
		     Provide one or more files in supported formats."
    )]
    data_files: Vec<Box<str>>,

    #[arg(
        long,
        value_enum,
        default_value = "zarr",
        help = "Backend format",
        long_help = "Specify the backend format to use for the merged data. \n\
		     Supported formats include 'zarr', 'h5', etc."
    )]
    backend: SparseIoBackend,

    #[arg(
        short,
        long,
        required = true,
        help = "Output file header",
        long_help = "Output file header: {output}.{backend} and {output}.batch.gz. \n\
		     The backend will contain everything. \n\
		     Batch assignment information will be saved in a separate file \n\
		     and is needed for embedding steps later."
    )]
    output: Box<str>,

    #[arg(
        long,
        default_value_t = false,
        help = "Squeeze sparse rows/columns",
        long_help = "Enable squeezing to remove rows and columns with too few non-zeros. \n\
		     This can help reduce file size and improve performance."
    )]
    do_squeeze: bool,

    #[arg(
        long,
        default_value_t = 1,
        help = "Row non-zero cutoff",
        long_help = "Minimum number of non-zero elements required for rows. \n\
		     Rows with fewer non-zeros will be removed if squeezing is enabled."
    )]
    row_nnz_cutoff: usize,

    #[arg(
        long,
        default_value_t = 1,
        help = "Column non-zero cutoff",
        long_help = "Minimum number of non-zero elements required for columns. \n\
		     Columns with fewer non-zeros will be removed if squeezing is enabled."
    )]
    column_nnz_cutoff: usize,

    #[arg(
        long,
        default_value = "100",
        help = "Block size for parallel processing",
        long_help = "Block size for parallel processing. \n\
		     Adjust this value to optimize performance for your hardware."
    )]
    block_size: usize,

    #[arg(
        short,
        long,
        action = clap::ArgAction::Count,
        help = "Verbose mode",
        long_help = "Enable verbose mode for more detailed output. \n\
		     Use multiple times for increased verbosity."
    )]
    verbose: u8,
}

#[derive(clap::Args, Debug)]
pub struct MergeMtxArgs {
    #[arg(
        value_delimiter = ',',
        required = true,
        help = "Input data directories",
        long_help = "Within each directory and its sub-directories, \n\
		     the program will search for files named as specified by \n\
                     (1) `mtx_file_name`, \n\
		     (2) `feature_file_name`, \n\
		     and (3) `barcode_file_name` \n\
		     to merge into one backend file."
    )]
    data_directories: Vec<Box<str>>,

    #[arg(
        long,
        value_enum,
        default_value = "zarr",
        help = "Backend format",
        long_help = "Specify the backend format for the merged data. \n\
                     Supported formats include 'zarr', 'h5', etc."
    )]
    backend: SparseIoBackend,

    #[arg(
        short,
        long,
        required = true,
        help = "Output file header",
        long_help = "Output file header: {output}.{backend} and {output}.batch.gz. \n\
                     The backend will contain all merged data. \n\
                     Batch assignment information will be saved in a separate file and \n\
		     is needed for embedding steps later."
    )]
    output: Box<str>,

    #[arg(
        short,
        long,
        default_value = "matrix.mtx",
        help = "Matrix file name",
        long_help = "Name of the matrix file to search for in each directory. \n\
                     The default for 10x data is 'matrix.mtx'."
    )]
    mtx_file_name: Box<str>,

    #[arg(
        short,
        long,
        default_value = "genes.tsv.gz",
        help = "Feature/row file name",
        long_help = "Name of the feature (row) file to search for in each directory. \n\
                     The default is 'genes.tsv.gz'."
    )]
    feature_file_name: Box<str>,

    #[arg(
        long,
        default_value_t = 2,
        help = "Number of words for feature names",
        long_help = "Number of words to use when parsing feature names from the feature file. \n\
                     Adjust this to match your data format."
    )]
    num_feature_name_words: usize,

    #[arg(
        short,
        long,
        default_value = "barcodes.tsv.gz",
        help = "Barcode/column file name",
        long_help = "Name of the barcode (column) file to search for in each directory. \n\
                     The default is 'barcodes.tsv.gz'."
    )]
    barcode_file_name: Box<str>,

    #[arg(
        long,
        default_value_t = 5,
        help = "Number of words for barcode names",
        long_help = "Number of words to use when parsing barcode names from the barcode file. \n\
                     Adjust this to match your data format."
    )]
    num_barcode_name_words: usize,

    #[arg(
        long,
        default_value_t = false,
        help = "Squeeze sparse rows/columns",
        long_help = "Enable squeezing to remove rows and columns with too few non-zeros. \n\
                     This can help reduce file size and improve performance."
    )]
    do_squeeze: bool,

    #[arg(
        long,
        default_value_t = 1,
        help = "Row non-zero cutoff",
        long_help = "Minimum number of non-zero elements required for rows. \n\
                     Rows with fewer non-zeros will be removed if squeezing is enabled."
    )]
    row_nnz_cutoff: usize,

    #[arg(
        long,
        default_value_t = 1,
        help = "Column non-zero cutoff",
        long_help = "Minimum number of non-zero elements required for columns. \n\
                     Columns with fewer non-zeros will be removed if squeezing is enabled."
    )]
    column_nnz_cutoff: usize,

    #[arg(
        short,
        long,
        action = clap::ArgAction::Count,
        help = "Verbose mode",
        long_help = "Enable verbose mode for more detailed output. \n\
                     Use multiple times for increased verbosity."
    )]
    verbose: u8,
}

#[derive(Args, Debug)]
#[command(about)]
pub struct RunSqueezeArgs {
    /// data files -- either `.zarr` or `.h5`
    #[arg(required = true)]
    data_files: Vec<Box<str>>,

    /// number of non-zero cutoff for rows
    #[arg(short, long, default_value = "0")]
    row_nnz_cutoff: usize,

    /// number of non-zero cutoff for columns
    #[arg(short, long, default_value = "0")]
    column_nnz_cutoff: usize,

    /// block_size for parallel processing
    #[arg(long, default_value = "100")]
    block_size: usize,

    /// preload data into memory for faster processing
    #[arg(
        long,
        alias = "preload-data",
        default_value_t = true,
        help = "Preload data into memory for faster processing",
        long_help = "Preload all column data into memory before squeezing. \n\
		     This can significantly speed up processing but requires more memory."
    )]
    preload: bool,

    /// show nnz histogram before squeezing
    #[arg(
        long,
        default_value_t = false,
        help = "Show ASCII histogram of row/column nnz distributions",
        long_help = "Display log1p-transformed ASCII histograms of row and column \n\
		     non-zero counts before squeezing. Helps determine appropriate cutoff values."
    )]
    show_histogram: bool,

    /// save histogram data to files
    #[arg(
        long,
        help = "Output file prefix for saving histogram data",
        long_help = "Save histogram data to {prefix}.row_nnz.txt and {prefix}.col_nnz.txt files. \n\
		     Each file contains nnz counts that can be used for further analysis."
    )]
    save_histogram: Option<Box<str>>,

    /// dry run - only show histograms without performing squeeze
    #[arg(
        long,
        default_value_t = false,
        help = "Preview mode - show histograms without squeezing",
        long_help = "Only display histograms and statistics without actually performing the squeeze operation. \n\
		     Useful for determining appropriate cutoff values."
    )]
    dry_run: bool,

    /// interactive mode - prompt user after showing histogram
    #[arg(
        short,
        long,
        default_value_t = false,
        help = "Interactive mode - ask for confirmation after showing histogram",
        long_help = "Show histogram and prompt user to proceed, adjust cutoffs, or cancel. \n\
		     Automatically enables --show-histogram."
    )]
    interactive: bool,

    /// output file for squeezed data
    #[arg(
        short,
        long,
        help = "Output file for squeezed data",
        long_help = "Save squeezed data to a new file instead of modifying in-place. \n\
		     With multiple inputs, all files will be squeezed and merged into {output}.{backend}. \n\
		     If not specified, modifies files in-place (requires confirmation in interactive mode)."
    )]
    output: Option<Box<str>>,

    /// row alignment strategy for merging multiple files
    #[arg(
        long,
        value_enum,
        default_value = "common",
        help = "Row alignment strategy when merging multiple files",
        long_help = "How to align rows across files after squeezing:\n\
		     - common: Keep only rows present in ALL files (intersection)\n\
		     - union: Keep rows present in ANY file (union, fills missing with zeros)"
    )]
    row_align: RowAlignMode,
}

#[derive(clap::ValueEnum, Clone, Debug, PartialEq)]
#[clap(rename_all = "lowercase")]
pub enum RowAlignMode {
    Common,
    Union,
}

#[derive(ValueEnum, Clone, Debug, PartialEq)]
#[clap(rename_all = "lowercase")]
enum StatDim {
    Row,
    Column,
}

#[derive(Args, Debug)]
pub struct RunStatArgs {
    #[arg(
        required = true,
        help = "Input data files in '.zarr' or '.h5' format",
        long_help = "Provide data files in either '.zarr' or '.h5' format. \n\
		     You can convert '.mtx' files to '.zarr' or '.h5' using\n\
		     the 'data-beans from-mtx' command."
    )]
    data_files: Vec<Box<str>>,

    #[arg(
        short,
        long,
        value_enum,
        help = "Statistics dimension (row or column)",
        long_help = "Choose whether to compute statistics over rows or columns."
    )]
    stat_dim: StatDim,

    #[arg(
        short,
        long,
        help = "Row name regex pattern for column statistics",
        long_help = "Specify a regex pattern to select row names \n\
		     when accumulating statistics over columns.\n\
		     Only rows matching this pattern will be included.\n\
		     Examples: '^MT-' (starts with MT-), 'GAPDH$' (ends with GAPDH),\n\
		     '^(MT|RPL|RPS)-' (mitochondrial or ribosomal genes).\n\
		     Matching is case-insensitive."
    )]
    row_name_pattern: Option<Box<str>>,

    #[arg(
        short = 'g',
        long,
        help = "Column group membership file for row statistics",
        long_help = "Provide a file that defines column group membership \n\
		     when accumulating statistics over rows. \n\
		     This provides statistics computed for group-wise analysis."
    )]
    column_group_file: Option<Box<str>>,

    #[arg(
        short = 'd',
        long,
        default_value = "@",
        help = "Delimiter for extracting base barcode from column names",
        long_help = "Delimiter character used to extract base barcode for matching. \n\
		     For example, with delimiter '@', column 'ACGT-1@batch1' matches \n\
		     membership key 'ACGT-1@batch2' via base key 'ACGT-1'."
    )]
    delimiter: char,

    #[arg(
        long,
        alias = "preload-data",
        default_value_t = false,
        help = "Preload data into memory for faster processing",
        long_help = "Preload all column data into memory before computing statistics. \n\
		     This can significantly speed up processing but requires more memory."
    )]
    preload: bool,

    #[arg(
        long,
        value_enum,
        default_value = "100",
        help = "Block size for processing",
        long_help = "Set the block size for processing data. \n\
		     Adjust this value to optimize performance for your hardware."
    )]
    block_size: usize,

    #[arg(
        short,
        long,
        default_value = "stdout",
        help = "Output statistics file",
        long_help = "Specify the output file for statistics. \n\
		     You can provide a '.parquet' file for efficient storage, \n\
		     or use 'stdout' to print results to the console."
    )]
    output: Box<str>,
}

/// A quick information of the underlying matrix of a backend file.
#[derive(Args, Debug)]
pub struct InfoArgs {
    /// data file -- .zarr or .h5 file
    data_file: Box<str>,

    /// file header for {output}.{rows.gz,columns.gz}
    #[arg(short, long, default_value = "")]
    output: Box<str>,
}

#[derive(clap::Args, Debug)]
pub struct RunSimulateArgs {
    #[arg(
        short,
        long,
        help = "Number of rows, genes, or features",
        long_help = "Set the number of rows, which typically corresponds to \n\
		     genes or features in the simulated matrix."
    )]
    rows: usize,

    #[arg(
        short,
        long,
        help = "Number of columns or cells",
        long_help = "Set the number of columns, which typically corresponds to \n\
		     cells in the simulated matrix."
    )]
    cols: usize,

    #[arg(
        short,
        long,
        default_value_t = 1000,
        help = "Depth per column (expected non-zero genes per cell)",
        long_help = "Specify the expected number of non-zero genes per cell.\n\
		     This controls the sparsity of the simulated data."
    )]
    depth: usize,

    #[arg(
        short,
        long,
        default_value_t = 1,
        help = "Number of factors (cell types, topics, states, etc.)",
        long_help = "Set the number of factors, which can represent \n\
		     cell types, topics, states, or other groupings in the simulation."
    )]
    factors: usize,

    #[arg(
        short,
        long,
        default_value_t = 1,
        help = "Number of batches",
        long_help = "Specify the number of batches in the simulation. \n\
		     Batch effects will be added if two or more batches are specified."
    )]
    batches: usize,

    #[arg(
        long,
        default_value_t = 1.0,
        help = "Proportion of variance explained by topic membership",
        long_help = "Set the proportion of variance explained by the topic effects.\n\
		     This controls how much topics influence the simulated data."
    )]
    pve_topic: f32,

    #[arg(
        long,
        default_value_t = 1.0,
        help = "Proportion of variance explained by batch effects",
        long_help = "Set the proportion of variance explained by batch effects. \n\
		     This parameter only takes effect when there are two or more batches."
    )]
    pve_batch: f32,

    #[arg(
        short,
        long,
        help = "Output file header",
        long_help = "Specify the output file header. The output will be named as {output}.{backend}."
    )]
    output: Box<str>,

    #[arg(
        long,
        default_value_t = 10.0,
        help = "Overdispersion φ parameter for β ~ Gamma(1/φ, K*φ)",
        long_help = "Set the overdispersion φ parameter for β ~ Gamma(1/φ, K*φ).\n\
		     The mean of β will be K. \n\
		     A high value (φ > 10) causes strong influences from βθ factorization, \n\
		     while a small value (φ < 5) weakens the factorization. \n\
		     φ = 10 is a reasonable default value."
    )]
    overdisp: f32,

    #[arg(
        long,
        default_value_t = 42,
        help = "Random seed",
        long_help = "Set the random seed for reproducibility of the simulation."
    )]
    rseed: u64,

    #[arg(
        long,
        default_value_t = false,
        help = "Save output in MTX format",
        long_help = "Enable this option to save the simulated matrix in MTX format \n\
		     in addition to the backend format."
    )]
    save_mtx: bool,

    #[arg(
        long,
        value_enum,
        default_value = "zarr",
        help = "Backend format for output",
        long_help = "Choose the backend format for the output file. \n\
		     Supported formats include 'zarr' and 'h5'."
    )]
    backend: SparseIoBackend,
}

/////////////////////
// implementations //
/////////////////////

// All handler functions have been moved to their respective modules:
// - read_row_names, read_col_names -> utilities/io_helpers.rs
// - run_build_from_mtx, run_build_from_h5_triplets, run_build_from_zarr_triplets -> handlers/builders.rs
// - list_h5, list_zarr -> handlers/listing.rs
// - show_info, take_columns, take_rows, take_column_names, take_row_names -> handlers/inspection.rs
// - run_merge_backend, run_merge_mtx, align_backends -> handlers/merging.rs
// - reorder_rows, subset_columns, run_squeeze -> handlers/transformation.rs
// - run_stat, run_simulate -> handlers/analysis.rs
